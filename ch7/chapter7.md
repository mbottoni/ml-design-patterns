
# Responsible AI


## Heuristic


## Explainable

- shap values


## Fairness

While Peter Parker may not have been referring to machine learning when he said,
“With great power comes great responsibility,” the quote certainly applies here. ML
has the power to disrupt industries, improve productivity, and generate new insights
from data. With this potential, it’s especially important that we understand how our
models will impact different groups of stakeholders. Model stakeholders could
include varying demographic slices of model users, regulatory groups, a data science
team, or business teams within an organization.
The Responsible AI patterns outlined in this chapter are an essential part of every ML
workflow—they can help us better understand the predictions generated by our mod‐
els and catch potential adverse behavior before models go to production. Starting
with the Heuristic Benchmark pattern, we looked at how to identify an initial metric
for model evaluation. This metric is useful as a comparison point for understanding
subsequent model versions and summarizing model behavior for business decision
makers. In the Explainable Predictions pattern, we demonstrated how to use feature
attributions to see which features were most important in signaling a model’s predic‐
tion. Feature attributions are one type of explainability method and can be used for
both evaluating the prediction on a single example or over a group of test inputs.
Finally, the Fairness Lens design pattern presented tools and metrics for ensuring a
model’s predictions treat all groups of users in a way that is fair, equitable, and
unbiased.
